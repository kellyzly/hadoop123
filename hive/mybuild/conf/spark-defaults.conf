#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
spark.master=yarn
deploy.mode=cluster
 spark.eventLog.enabled=true
 spark.eventLog.dir=hdfs://bdpe42:8020/spark-history-server/hos20
 spark.history.fs.logDirectory=hdfs://bdpe42:8020/spark-history-server/hos20
 spark.history.fs.update.interval=10
#spark.executor.userClassPathFirst=true
# spark.yarn.jars=local:/home/zly/spark-2.0.0-bin-hadoop2-without-hive/jars/*
 #spark.yarn.jars=hdfs://bdpe42:8020/spark-2.0.0-bin-hadoop/*
 # spark.yarn.archive is hdfs file, it meets problem
# spark.yarn.archive=hdfs://bdpe42:8020/spark-archive.zip
spark.executor.instances 5
 spark.executor.cores 4
#spark.dynamicAllocation.enabled=true
#spark.dynamicAllocation.initialExecutors=3
#spark.dynamicAllocation.maxExecutors=500
#spark.dynamicAllocation.minExecutors=3
#spark.dynamicAllocation.schedulerBacklogTimeout=5
#spark.dynamicAllocation.sustainedSchedulerBacklogTimeout=5
#spark.dynamicAllocation.cachedExecutorIdleTimeout=900
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryo.referenceTracking=false
#spark.local.dir=/home/spark/tmp/



 #spark.yarn.archive=/home/zly/spark-2.0.0-bin-hadoop2-without-hive/spark-archive.zip
# spark.yarn.archive=hdfs://bdpe42:8020/spark-
spark.executor.extraJavaOptions=-Dlog4j.configuration=file:/home/zly/hos/spark/conf/log4j.properties
spark.driver.extraJavaOptions=-Dlog4j.configuration=file:/home/zly/hos/spark/conf/log4j.properties
 spark.executor.memory	7000m
 spark.yarn.executor.memoryOverhead 1966
# spark.executor.instances 6
#spark.memory.fraction 0.8
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
